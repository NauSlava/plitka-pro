# predict.py - –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ "nauslava/plitka-pro-project:v4.4.36"
# –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ù–ê–®–£ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å LoRA –∏ Textual Inversion (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ü–ï–†–ï–ü–£–¢–ê–ù–ù–´–• –†–ê–ó–ú–ï–†–û–í)

import os
import torch
import random
import gc
import json
import logging
from typing import Optional, List, Dict, Any
from PIL import Image, ImageDraw, ImageColor
import numpy as np
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
os.environ["HF_HOME"] = "/tmp/hf_home"
os.environ["HF_DATASETS_CACHE"] = "/tmp/hf_datasets_cache"
os.environ["HF_MODELS_CACHE"] = "/tmp/hf_cache"
os.environ["TRANSFORMERS_CACHE_MIGRATION_DISABLE"] = "1"
os.environ["HF_HUB_CACHE_MIGRATION_DISABLE"] = "1"
os.environ["HF_HUB_DISABLE_TELEMETRY"] = "1"
os.environ["HF_HUB_DISABLE_PROGRESS_BARS"] = "1"
os.environ["TRANSFORMERS_VERBOSITY"] = "error"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler
from transformers import CLIPTextModel, T5EncoderModel
from cog import BasePredictor, Input

class Predictor(BasePredictor):
    def __init__(self):
        self.device = None
        self.pipe = None
    
    def setup(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–µ—Ä–∞."""
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ v4.4.37-pre (–ö–ê–ß–ï–°–¢–í–û/–ê–ù–¢–ò-–ú–û–ó–ê–ò–ö–ê/LEGEND)...")
        
        # 1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        if torch.cuda.is_available():
            self.device = "cuda"
            # –í—ã–±–æ—Ä GPU —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –ø–∞–º—è—Ç—å—é
            best_gpu = max(range(torch.cuda.device_count()), 
                          key=lambda i: torch.cuda.get_device_properties(i).total_memory)
            torch.cuda.set_device(best_gpu)
            logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: {torch.cuda.get_device_name(best_gpu)}")
            logger.info(f"üìä –ü–∞–º—è—Ç—å GPU: {torch.cuda.get_device_properties(best_gpu).total_memory / 1024**3:.1f} GB")
        else:
            self.device = "cpu"
            logger.info("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
        
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ SDXL pipeline
        logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ SDXL...")
        self.pipe = StableDiffusionXLPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-base-1.0",
            torch_dtype=torch.float16,
            use_safetensors=True,
            variant="fp16",
            resume_download=False
        )
        
        # 3. –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –Ω–∞ GPU
        self.pipe = self.pipe.to(self.device)
        if self.device == "cuda":
            try:
                self.pipe.enable_xformers_memory_efficient_attention()
            except Exception:
                pass
            try:
                torch.backends.cudnn.benchmark = True
            except Exception:
                pass
        
        # 4. –ó–∞–≥—Ä—É–∑–∫–∞ –ù–ê–®–ò–• –æ–±—É—á–µ–Ω–Ω—ã—Ö LoRA (—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API)
        logger.info("üîß –ó–∞–≥—Ä—É–∑–∫–∞ –ù–ê–®–ò–• LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤...")
        lora_path = "/src/model_files/rubber-tile-lora-v4_sdxl_lora.safetensors"
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å –∏–º–µ–Ω–µ–º –∞–¥–∞–ø—Ç–µ—Ä–∞ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–µ—Å 0.75 (–∏–∑ –ø—Ä–æ—Ñ–∏–ª—è)
            self.pipe.load_lora_weights(lora_path, adapter_name="rt")
            if hasattr(self.pipe, "set_adapters"):
                self.pipe.set_adapters(["rt"], adapter_weights=[0.75])
                try:
                    self.pipe.fuse_lora()
                except Exception:
                    # –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö fuse_lora –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ
                    pass
                logger.info("‚úÖ LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã (weight=0.75)")
            else:
                # –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º–∏ diffusers: set_adapters –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                try:
                    if hasattr(self.pipe, "fuse_lora"):
                        self.pipe.fuse_lora()
                except Exception:
                    pass
                logger.info("‚ÑπÔ∏è set_adapters –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏ diffusers; –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –≤–µ—Å LoRA")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ LoRA: {e}")
            raise e
        
        # 5. –î–ï–¢–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –†–ê–ó–ú–ï–†–û–í SDXL
        logger.info("üîç –î–ï–¢–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –†–ê–ó–ú–ï–†–û–í SDXL...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã text_encoder –î–û –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
        logger.info("üìä –ê–ù–ê–õ–ò–ó –†–ê–ó–ú–ï–†–û–í –î–û –î–û–ë–ê–í–õ–ï–ù–ò–Ø –¢–û–ö–ï–ù–û–í:")
        
        # text_encoder (–ø–µ—Ä–≤—ã–π)
        emb_1 = self.pipe.text_encoder.get_input_embeddings()
        logger.info(f"üîç text_encoder.get_input_embeddings().weight.shape: {emb_1.weight.shape}")
        logger.info(f"üîç text_encoder.config.hidden_size: {self.pipe.text_encoder.config.hidden_size}")
        logger.info(f"üîç text_encoder.config.vocab_size: {self.pipe.text_encoder.config.vocab_size}")
        
        # text_encoder_2 (–≤—Ç–æ—Ä–æ–π)
        emb_2 = self.pipe.text_encoder_2.get_input_embeddings()
        logger.info(f"üîç text_encoder_2.get_input_embeddings().weight.shape: {emb_2.weight.shape}")
        logger.info(f"üîç text_encoder_2.config.hidden_size: {self.pipe.text_encoder_2.config.hidden_size}")
        logger.info(f"üîç text_encoder_2.config.vocab_size: {self.pipe.text_encoder_2.config.vocab_size}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤
        logger.info(f"üîç tokenizer.vocab_size: {self.pipe.tokenizer.vocab_size}")
        logger.info(f"üîç tokenizer_2.vocab_size: {self.pipe.tokenizer_2.vocab_size}")
        
        # 6. –ó–∞–≥—Ä—É–∑–∫–∞ –ù–ê–®–ò–• –æ–±—É—á–µ–Ω–Ω—ã—Ö Textual Inversion (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ü–ï–†–ï–ü–£–¢–ê–ù–ù–´–• –†–ê–ó–ú–ï–†–û–í)
        logger.info("üî§ –ó–∞–≥—Ä—É–∑–∫–∞ –ù–ê–®–ò–• Textual Inversion (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ü–ï–†–ï–ü–£–¢–ê–ù–ù–´–• –†–ê–ó–ú–ï–†–û–í)...")
        ti_path = "/src/model_files/rubber-tile-lora-v4_sdxl_embeddings.safetensors"
        try:
            # –†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ dual-encoder Textual Inversion –¥–ª—è SDXL
            try:
                from safetensors.torch import load_file
                state_dict = load_file(ti_path)
                logger.info("‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω —á–µ—Ä–µ–∑ safetensors.load_file")
            except ImportError:
                logger.warning("‚ö†Ô∏è safetensors –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º torch.load")
                try:
                    state_dict = torch.load(ti_path, map_location="cpu")
                    logger.info("‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω —á–µ—Ä–µ–∑ torch.load")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ torch.load: {e}")
                    raise e
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ safetensors: {e}")
                raise e
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            if not isinstance(state_dict, dict):
                logger.error("‚ùå –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º")
                raise ValueError("Invalid file format")
            
            logger.info(f"üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ state_dict: {list(state_dict.keys())}")
            
            # –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ê–ó–ú–ï–†–û–í –≠–ú–ë–ï–î–î–ò–ù–ì–û–í
            logger.info("üîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ê–ó–ú–ï–†–û–í –≠–ú–ë–ï–î–î–ò–ù–ì–û–í:")
            
            if 'clip_g' in state_dict:
                embeddings_0 = state_dict['clip_g']
                logger.info(f"üìä clip_g (embeddings_0) —Ä–∞–∑–º–µ—Ä: {embeddings_0.shape}")
                logger.info(f"üîç clip_g —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 0: {embeddings_0.shape[0]}")
                logger.info(f"üîç clip_g —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 1: {embeddings_0.shape[1]}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å text_encoder_2 (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï!)
                emb_2_hidden_size = self.pipe.text_encoder_2.config.hidden_size
                logger.info(f"üîç text_encoder_2.config.hidden_size: {emb_2_hidden_size}")
                logger.info(f"üîç –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å clip_g —Å text_encoder_2: {embeddings_0.shape[1]} == {emb_2_hidden_size}")
                
            if 'clip_l' in state_dict:
                embeddings_1 = state_dict['clip_l']
                logger.info(f"üìä clip_l (embeddings_1) —Ä–∞–∑–º–µ—Ä: {embeddings_1.shape}")
                logger.info(f"üîç clip_l —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 0: {embeddings_1.shape[0]}")
                logger.info(f"üîç clip_l —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 1: {embeddings_1.shape[1]}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å text_encoder (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï!)
                emb_1_hidden_size = self.pipe.text_encoder.config.hidden_size
                logger.info(f"üîç text_encoder.config.hidden_size: {emb_1_hidden_size}")
                logger.info(f"üîç –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å clip_l —Å text_encoder: {embeddings_1.shape[1]} == {emb_1_hidden_size}")
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—ã
            logger.info("üî§ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—ã...")
            self.pipe.tokenizer.add_tokens(["<s0>", "<s1>"])
            self.pipe.tokenizer_2.add_tokens(["<s0>", "<s1>"])
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ ID —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–Ω–∏—Ü
            token_ids_one = self.pipe.tokenizer.convert_tokens_to_ids(["<s0>", "<s1>"])
            token_ids_two = self.pipe.tokenizer_2.convert_tokens_to_ids(["<s0>", "<s1>"])
            
            logger.info(f"üî§ ID —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è tokenizer: {token_ids_one}")
            logger.info(f"üî§ ID —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è tokenizer_2: {token_ids_two}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ embedding —Å–ª–æ–µ–≤ –ü–û–°–õ–ï –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
            logger.info("üìä –ê–ù–ê–õ–ò–ó –†–ê–ó–ú–ï–†–û–í –ü–û–°–õ–ï –î–û–ë–ê–í–õ–ï–ù–ò–Ø –¢–û–ö–ï–ù–û–í:")
            
            emb_one_size = self.pipe.text_encoder.get_input_embeddings().weight.shape[0]
            emb_two_size = self.pipe.text_encoder_2.get_input_embeddings().weight.shape[0]
            
            logger.info(f"üìä –†–∞–∑–º–µ—Ä embedding —Å–ª–æ—è text_encoder: {emb_one_size}")
            logger.info(f"üìä –†–∞–∑–º–µ—Ä embedding —Å–ª–æ—è text_encoder_2: {emb_two_size}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
            max_id_one = max(token_ids_one)
            max_id_two = max(token_ids_two)
            
            if max_id_one >= emb_one_size:
                logger.info(f"üîß –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ embedding —Å–ª–æ—è text_encoder —Å {emb_one_size} –Ω–∞ {max_id_one + 1}")
                self.pipe.text_encoder.resize_token_embeddings(len(self.pipe.tokenizer))
                emb_one_size = self.pipe.text_encoder.get_input_embeddings().weight.shape[0]
                logger.info(f"‚úÖ –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä embedding —Å–ª–æ—è text_encoder: {emb_one_size}")
            
            if max_id_two >= emb_two_size:
                logger.info(f"üîß –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ embedding —Å–ª–æ—è text_encoder_2 —Å {emb_two_size} –Ω–∞ {max_id_two + 1}")
                self.pipe.text_encoder_2.resize_token_embeddings(len(self.pipe.tokenizer_2))
                emb_two_size = self.pipe.text_encoder_2.get_input_embeddings().weight.shape[0]
                logger.info(f"‚úÖ –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä embedding —Å–ª–æ—è text_encoder_2: {emb_two_size}")
            
            # –ü–û–ü–´–¢–ö–ê –ó–ê–ì–†–£–ó–ö–ò –° –ü–†–û–í–ï–†–ö–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï!)
            logger.info("üîß –ü–û–ü–´–¢–ö–ê –ó–ê–ì–†–£–ó–ö–ò –≠–ú–ë–ï–î–î–ò–ù–ì–û–í –° –ü–†–û–í–ï–†–ö–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï!):")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ó–∞–≥—Ä—É–∂–∞–µ–º clip_g (1280) –≤ text_encoder_2 (1280)
            if 'clip_g' in state_dict:
                embeddings_0 = state_dict['clip_g']
                logger.info(f"üìä –†–∞–∑–º–µ—Ä embeddings_0 (clip_g): {embeddings_0.shape}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ —Å text_encoder_2
                emb_2_hidden_size = self.pipe.text_encoder_2.config.hidden_size
                if embeddings_0.shape[1] == emb_2_hidden_size:
                    logger.info(f"‚úÖ clip_g —Å–æ–≤–º–µ—Å—Ç–∏–º —Å text_encoder_2: {embeddings_0.shape[1]} == {emb_2_hidden_size}")
                    if embeddings_0.shape[0] >= 2 and token_ids_two[0] < emb_two_size and token_ids_two[1] < emb_two_size:
                        self.pipe.text_encoder_2.get_input_embeddings().weight.data[token_ids_two[0]] = embeddings_0[0]
                        self.pipe.text_encoder_2.get_input_embeddings().weight.data[token_ids_two[1]] = embeddings_0[1]
                        logger.info("‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ clip_g –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ text_encoder_2 (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï!)")
                    else:
                        logger.error(f"‚ùå –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–æ–≤: embeddings_0={embeddings_0.shape}, token_ids={token_ids_two}, emb_size={emb_two_size}")
                        raise ValueError("Embedding size mismatch")
                else:
                    logger.warning(f"‚ö†Ô∏è clip_g –ù–ï —Å–æ–≤–º–µ—Å—Ç–∏–º —Å text_encoder_2: {embeddings_0.shape[1]} != {emb_2_hidden_size}")
                    logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É clip_g –≤ text_encoder_2")
            else:
                logger.warning("‚ö†Ô∏è –ö–ª—é—á 'clip_g' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ state_dict")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ó–∞–≥—Ä—É–∂–∞–µ–º clip_l (768) –≤ text_encoder (768)
            if 'clip_l' in state_dict:
                embeddings_1 = state_dict['clip_l']
                logger.info(f"üìä –†–∞–∑–º–µ—Ä embeddings_1 (clip_l): {embeddings_1.shape}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–æ–≤ —Å text_encoder
                emb_1_hidden_size = self.pipe.text_encoder.config.hidden_size
                if embeddings_1.shape[1] == emb_1_hidden_size:
                    logger.info(f"‚úÖ clip_l —Å–æ–≤–º–µ—Å—Ç–∏–º —Å text_encoder: {embeddings_1.shape[1]} == {emb_1_hidden_size}")
                    if embeddings_1.shape[0] >= 2 and token_ids_one[0] < emb_one_size and token_ids_one[1] < emb_one_size:
                        self.pipe.text_encoder.get_input_embeddings().weight.data[token_ids_one[0]] = embeddings_1[0]
                        self.pipe.text_encoder.get_input_embeddings().weight.data[token_ids_one[1]] = embeddings_1[1]
                        logger.info("‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ clip_l –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ text_encoder (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï!)")
                    else:
                        logger.error(f"‚ùå –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–æ–≤: embeddings_1={embeddings_1.shape}, token_ids={token_ids_one}, emb_size={emb_one_size}")
                        raise ValueError("Embedding size mismatch")
                else:
                    logger.warning(f"‚ö†Ô∏è clip_l –ù–ï —Å–æ–≤–º–µ—Å—Ç–∏–º —Å text_encoder: {embeddings_1.shape[1]} != {emb_1_hidden_size}")
                    logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É clip_l –≤ text_encoder")
            else:
                logger.warning("‚ö†Ô∏è –ö–ª—é—á 'clip_l' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ state_dict")
            
            logger.info("‚úÖ Textual Inversion –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ü–ï–†–ï–ü–£–¢–ê–ù–ù–´–• –†–ê–ó–ú–ï–†–û–í)")
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Textual Inversion: {e}")
            logger.error(f"üìä –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {type(e).__name__}: {str(e)}")
            logger.error("üîÑ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –±–µ–∑ Textual Inversion (–∫–∞—á–µ—Å—Ç–≤–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–Ω–∏–∂–µ–Ω–æ)")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ Textual Inversion, –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å
        
        # 7. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
        logger.info("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞...")
        self.pipe.scheduler = DPMSolverMultistepScheduler.from_config(
            self.pipe.scheduler.config,
            algorithm_type="dpmsolver++",
            use_karras_sigmas=True
        )
        
        # 8. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ VAE
        logger.info("üöÄ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ VAE –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π...")
        self.pipe.vae.enable_slicing()
        # –û—Ç–∫–ª—é—á–∞–µ–º tiling, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å "–ø—ç—á–≤–æ—Ä–∫"-–∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        # self.pipe.vae.enable_tiling()
        try:
            # –§–æ—Ä–º–∞—Ç –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            self.pipe.unet.to(memory_format=torch.channels_last)
            self.pipe.vae.to(memory_format=torch.channels_last)
        except Exception:
            pass
        
        # 9. –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        
        logger.info("üéâ –ú–æ–¥–µ–ª—å v4.4.36 —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ü–ï–†–ï–ü–£–¢–ê–ù–ù–´–• –†–ê–ó–ú–ï–†–û–í)!")
    
    def _build_prompt(self, colors: List[Dict[str, Any]], angle: int) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ù–ê–®–ò–• –æ–±—É—á–µ–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (–∫–∞–∫ –≤ v45)."""
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —Å –ù–ê–®–ò–ú–ò —Ç–æ–∫–µ–Ω–∞–º–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (–∫–∞–∫ –≤ v45)
        base_prompt = "ohwx_rubber_tile <s0><s1>"
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ü–≤–µ—Ç–æ–≤
        color_parts = []
        for color in colors:
            name = color["name"]
            proportion = color["proportion"]
            percentage = int(proportion * 100)
            color_parts.append(f"{percentage}% {name}")
        
        color_description = ", ".join(color_parts)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ü–≤–µ—Ç–æ–≤
        full_prompt = f"{base_prompt}, {color_description}"
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤
        quality_descriptors = [
            "photorealistic rubber tile",
            "high quality",
            "detailed texture",
            "professional photography",
            "sharp focus"
        ]
        
        full_prompt += ", " + ", ".join(quality_descriptors)
        
        return full_prompt
    
    def _build_negative_prompt(self) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞."""
        return (
            "text, watermark, logo, signature, blur, low quality, distorted, object,"
            " blurry, worst quality, deformed, 3d render, cartoon, abstract, painting,"
            " drawing, sketch, low resolution, mosaic, checkerboard, grid, patchwork,"
            " tiled, square blocks, seams, borders, rectangles, collage, large blocks"
        )

    def _parse_percent_colors(self, simple_prompt: str) -> List[Dict[str, Any]]:
        """–ü—Ä–æ—Å—Ç–µ–Ω—å–∫–∏–π –ø–∞—Ä—Å–µ—Ä —Å—Ç—Ä–æ–∫ –≤–∏–¥–∞ '60% red, 40% white' ‚Üí —Å–ø–∏—Å–æ–∫ —Ü–≤–µ—Ç–æ–≤ –∏ –¥–æ–ª–µ–π [0..1]."""
        parts = [p.strip() for p in simple_prompt.split(',') if p.strip()]
        result: List[Dict[str, Any]] = []
        for p in parts:
            try:
                percent_str, name = p.split('%', 1)
                percent = float(percent_str.strip())
                color_name = name.strip()
                if color_name.lower().startswith(('of ', ' ')):
                    color_name = color_name.split()[-1]
                result.append({"name": color_name, "proportion": max(0.0, min(1.0, percent / 100.0))})
            except Exception:
                continue
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –µ—Å–ª–∏ —Å—É–º–º–∞ –Ω–µ 1.0
        total = sum(c["proportion"] for c in result) or 1.0
        for c in result:
            c["proportion"] = c["proportion"] / total
        return result

    def _render_legend(self, colors: List[Dict[str, Any]], size: int = 256) -> Image.Image:
        """–°—Ç—Ä–æ–∏–º –ø—Ä–æ—Å—Ç—É—é –ª–µ–≥–µ–Ω–¥—É/colormap –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–æ–ø–æ—Ä—Ü–∏–π (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª–æ—Å—ã)."""
        img = Image.new('RGB', (size, size), color='white')
        draw = ImageDraw.Draw(img)
        y = 0
        for c in colors:
            h = max(1, int(size * c["proportion"]))
            try:
                rgb = ImageColor.getrgb(c["name"])  # —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ü–≤–µ—Ç–∞
            except Exception:
                rgb = (200, 200, 200)
            draw.rectangle([0, y, size, min(size, y + h)], fill=rgb)
            y += h
        # –ü–æ–¥–≥–æ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–æ–ª–æ—Å—É –¥–æ –∫—Ä–∞—è
        if y < size and colors:
            try:
                rgb_last = ImageColor.getrgb(colors[-1]["name"])
            except Exception:
                rgb_last = (200, 200, 200)
            draw.rectangle([0, y, size, size], fill=rgb_last)
        return img
    
    def _build_prompt_from_simple(self, simple_prompt: str) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –≤ –ø–æ–ª–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å –ù–ê–®–ò–ú–ò —Ç–æ–∫–µ–Ω–∞–º–∏ (–∫–∞–∫ –≤ v45)."""
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —Å –ù–ê–®–ò–ú–ò —Ç–æ–∫–µ–Ω–∞–º–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (–∫–∞–∫ –≤ v45)
        base_prompt = "ohwx_rubber_tile <s0><s1>"
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (–±–µ–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è base_prompt)
        if simple_prompt.startswith("ohwx_rubber_tile"):
            # –ï—Å–ª–∏ –ø—Ä–æ–º–ø—Ç —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç base_prompt, –Ω–µ –¥—É–±–ª–∏—Ä—É–µ–º
            full_prompt = simple_prompt
        else:
            # –ï—Å–ª–∏ –ø—Ä–æ–º–ø—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç base_prompt, –¥–æ–±–∞–≤–ª—è–µ–º
            full_prompt = f"{base_prompt}, {simple_prompt}"
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤
        quality_descriptors = [
            "photorealistic rubber tile",
            "high quality",
            "detailed texture",
            "professional photography",
            "sharp focus"
        ]
        
        full_prompt += ", " + ", ".join(quality_descriptors)
        
        return full_prompt
    
    def predict(self, prompt: str = Input(description="–û–ø–∏—Å–∞–Ω–∏–µ —Ü–≤–µ—Ç–æ–≤ —Ä–µ–∑–∏–Ω–æ–≤–æ–π –ø–ª–∏—Ç–∫–∏", default="100% red"), 
                negative_prompt: Optional[str] = Input(description="–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç", default=None), 
                seed: int = Input(description="–°–∏–¥ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏", default=-1)) -> List[Path]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–µ–∑–∏–Ω–æ–≤–æ–π –ø–ª–∏—Ç–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ù–ê–®–ï–ô –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."""
        
        try:
            logger.info("üé® –ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
            logger.info(f"üìù –í—Ö–æ–¥–Ω–æ–π –ø—Ä–æ–º–ø—Ç: {prompt}")
            logger.info(f"üö´ –í—Ö–æ–¥–Ω–æ–π –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {negative_prompt}")
            logger.info(f"üé≤ –í—Ö–æ–¥–Ω–æ–π —Å–∏–¥: {seed}")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (—É–¥–∞–ª–µ–Ω–∏–µ JSON-–æ–±–µ—Ä—Ç–∫–∏)
            if isinstance(prompt, str) and prompt.strip().startswith('{'):
                try:
                    import json
                    prompt_data = json.loads(prompt)
                    if isinstance(prompt_data, dict) and "prompt" in prompt_data:
                        prompt = prompt_data["prompt"]
                        logger.info(f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω JSON-–ø—Ä–æ–º–ø—Ç: {prompt}")
                except json.JSONDecodeError:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON-–ø—Ä–æ–º–ø—Ç: {prompt}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–º–ø—Ç–∞: {e}")
            
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            if negative_prompt is None:
                negative_prompt = self._build_negative_prompt()
                logger.info(f"üîß –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {negative_prompt}")
            
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏–¥–∞
            if seed == -1:
                seed = random.randint(0, 999999999)
                logger.info(f"üé≤ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å–ª—É—á–∞–π–Ω—ã–π —Å–∏–¥: {seed}")
            
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(seed)
                torch.cuda.manual_seed_all(seed)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –≤ –ø–æ–ª–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å –ù–ê–®–ò–ú–ò —Ç–æ–∫–µ–Ω–∞–º–∏
            full_prompt = self._build_prompt_from_simple(prompt)
            
            logger.info(f"üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
            logger.info(f"üìù –ü–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {full_prompt}")
            logger.info(f"üö´ –§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {negative_prompt}")
            logger.info(f"üé≤ –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–¥: {seed}")
            logger.info(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            logger.info("üöÄ –ó–∞–ø—É—Å–∫ pipeline –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
            result = self.pipe(
                prompt=full_prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=35,
                guidance_scale=6.7,
                width=1024,
                height=1024,
                generator=torch.Generator(device=self.device).manual_seed(seed)
            )
            logger.info("‚úÖ Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            final_image = result.images[0]
            logger.info(f"üìä –†–∞–∑–º–µ—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {final_image.size}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ preview (—É–º–µ–Ω—å—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
            preview_image = final_image.resize((512, 512), Image.Resampling.LANCZOS)
            logger.info("‚úÖ Preview –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
            final_path = "/tmp/final.png"
            preview_path = "/tmp/preview.png"
            
            final_image.save(final_path)
            preview_image.save(preview_path)
            logger.info("‚úÖ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ colormap (–ª–µ–≥–µ–Ω–¥—ã) –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            colormap_path = "/tmp/colormap.png"
            try:
                parsed_colors = self._parse_percent_colors(prompt)
                if not parsed_colors:
                    parsed_colors = [{"name": "white", "proportion": 1.0}]
                colormap_image = self._render_legend(parsed_colors, size=256)
                colormap_image.save(colormap_path)
                logger.info("‚úÖ Colormap —Å–æ–∑–¥–∞–Ω –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –ø—Ä–æ–ø–æ—Ä—Ü–∏–π")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å colormap: {e}")
                Image.new('RGB', (256, 256), color='white').save(colormap_path)
            
            # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()
            logger.info("üßπ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞")
            
            logger.info("‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!")
            
            return [Path(preview_path), Path(final_path), Path(colormap_path)]
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            logger.error(f"üìä –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
            logger.error(f"üìä –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {str(e)}")
            raise e
