# predict.py
from cog import BasePredictor, Input, Path
from typing import List, Dict, Any, Tuple, Optional
import json
import os
import random
import time
import logging
import warnings
import psutil
import threading

import numpy as np
from PIL import Image
import cv2

import torch
from safetensors.torch import load_file as load_safetensors
from diffusers import (
    StableDiffusionXLControlNetPipeline,
    ControlNetModel,
    EulerDiscreteScheduler,
)

# –£–õ–¨–¢–ò–ú–ê–¢–ò–í–ù–û–ï –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –í–°–ï–• –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ê–ì–†–ï–°–°–ò–í–ù–û
import warnings
warnings.filterwarnings("ignore")
warnings.simplefilter("ignore")
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", message=".*")
warnings.filterwarnings("ignore", message=".*_register_pytree_node.*")
warnings.filterwarnings("ignore", message=".*torch.utils._pytree.*")
warnings.filterwarnings("ignore", message=".*The `scheduler_config`.*")
warnings.filterwarnings("ignore", message=".*`torch.utils._pytree`.*")
warnings.filterwarnings("ignore", message=".*`torch.utils._pytree`.*")
warnings.filterwarnings("ignore", message=".*`torch.utils._pytree`.*")

# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –∏–∑ –ª–æ–≥–æ–≤
warnings.filterwarnings("ignore", message=".*torch.utils._pytree._register_pytree_node.*")
warnings.filterwarnings("ignore", message=".*Please use `torch.utils._pytree.register_pytree_node`.*")
warnings.filterwarnings("ignore", message=".*Loaded state dictonary is incorrect.*")
warnings.filterwarnings("ignore", message=".*Please verify that the loaded state dictionary.*")
warnings.filterwarnings("ignore", message=".*string_to_param.*")

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–∏—Å—Ç–µ–º—ã
import os
os.environ['PYTHONWARNINGS'] = 'ignore'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# üöÄ –ù–û–í–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –û–ö–†–£–ñ–ï–ù–ò–Ø –î–õ–Ø –£–ü–†–ê–í–õ–ï–ù–ò–Ø GPU/NPU
os.environ['CUDA_MEMORY_FRACTION'] = '0.7'  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞–∫—Å–∏–º—É–º 70% –ø–∞–º—è—Ç–∏ GPU
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'    # –°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è
os.environ['CUDA_CACHE_DISABLE'] = '0'      # –í–∫–ª—é—á–∏—Ç—å –∫—ç—à CUDA –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# üöÄ –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
class ResourceMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU/NPU —Ä–µ—Å—É—Ä—Å–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏."""
    
    def __init__(self, device_info: Dict[str, Any]):
        self.device_info = device_info
        self.monitoring = False
        self.monitor_thread = None
        self.max_memory_usage = 0.0
        self.max_gpu_utilization = 0.0
        
    def start_monitoring(self):
        """–ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        if self.monitoring:
            return
            
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        logger.info("üöÄ Resource monitoring started")
    
    def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1.0)
        logger.info("‚èπÔ∏è Resource monitoring stopped")
    
    def _monitor_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        while self.monitoring:
            try:
                if self.device_info['type'] == 'cuda':
                    self._monitor_gpu()
                elif self.device_info['type'] == 'npu':
                    self._monitor_npu()
                
                time.sleep(2.0)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã
            except Exception as e:
                logger.warning(f"Resource monitoring error: {e}")
                time.sleep(5.0)
    
    def _monitor_gpu(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU —Ä–µ—Å—É—Ä—Å–æ–≤."""
        try:
            if torch.cuda.is_available():
                # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ GPU
                allocated = torch.cuda.memory_allocated(self.device_info['id']) / (1024**3)
                reserved = torch.cuda.memory_reserved(self.device_info['id']) / (1024**3)
                total = self.device_info['memory']
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                self.max_memory_usage = max(self.max_memory_usage, allocated)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤ (50-80%)
                memory_usage_percent = (allocated / total) * 100
                if memory_usage_percent > 80:
                    logger.warning(f"‚ö†Ô∏è GPU memory usage: {memory_usage_percent:.1f}% (allocated: {allocated:.2f}GB, reserved: {reserved:.2f}GB)")
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–∞
                    torch.cuda.empty_cache()
                elif memory_usage_percent > 70:
                    logger.info(f"‚ÑπÔ∏è GPU memory usage: {memory_usage_percent:.1f}% (allocated: {allocated:.2f}GB)")
                
                # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≥—Ä—É–∑–∫–∏ GPU (—á–µ—Ä–µ–∑ nvidia-smi –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                try:
                    import subprocess
                    result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                                         capture_output=True, text=True, timeout=5)
                    if result.returncode == 0:
                        gpu_util = float(result.stdout.strip())
                        self.max_gpu_utilization = max(self.max_gpu_utilization, gpu_util)
                        
                        if gpu_util > 80:
                            logger.warning(f"‚ö†Ô∏è GPU utilization: {gpu_util:.1f}%")
                        elif gpu_util > 70:
                            logger.info(f"‚ÑπÔ∏è GPU utilization: {gpu_util:.1f}%")
                except:
                    pass  # nvidia-smi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                    
        except Exception as e:
            logger.debug(f"GPU monitoring error: {e}")
    
    def _monitor_npu(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ NPU —Ä–µ—Å—É—Ä—Å–æ–≤."""
        try:
            # –î–ª—è NPU –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∫–∞–∫ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            
            if cpu_percent > 80:
                logger.warning(f"‚ö†Ô∏è NPU system CPU usage: {cpu_percent:.1f}%")
            elif cpu_percent > 70:
                logger.info(f"‚ÑπÔ∏è NPU system CPU usage: {cpu_percent:.1f}%")
                
            if memory_percent > 80:
                logger.warning(f"‚ö†Ô∏è NPU system memory usage: {memory_percent:.1f}%")
            elif memory_percent > 70:
                logger.info(f"‚ÑπÔ∏è NPU system memory usage: {memory_percent:.1f}%")
                
        except Exception as e:
            logger.debug(f"NPU monitoring error: {e}")
    
    def get_resource_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Ä–µ—Å—É—Ä—Å–æ–≤."""
        return {
            'device_type': self.device_info['type'],
            'device_name': self.device_info['name'],
            'max_memory_usage_gb': self.max_memory_usage,
            'max_gpu_utilization_percent': self.max_gpu_utilization,
            'monitoring_active': self.monitoring
        }

# üöÄ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –î–õ–Ø MULTI-GPU –ò NPU
def select_best_device():
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (GPU/NPU/CPU)."""
    device_info = {
        'type': 'cpu',
        'id': None,
        'name': 'CPU',
        'memory': 0
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA GPU
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        logger.info(f"Found {gpu_count} CUDA GPU(s)")
        
        # –í—ã–±–æ—Ä GPU —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –ø–∞–º—è—Ç—å—é
        best_gpu = 0
        max_memory = 0
        
        for i in range(gpu_count):
            try:
                torch.cuda.set_device(i)
                props = torch.cuda.get_device_properties(i)
                memory_gb = props.total_memory / (1024**3)
                logger.info(f"GPU {i}: {props.name} - {memory_gb:.1f}GB")
                
                if memory_gb > max_memory:
                    max_memory = memory_gb
                    best_gpu = i
                    device_info = {
                        'type': 'cuda',
                        'id': i,
                        'name': props.name,
                        'memory': memory_gb
                    }
            except Exception as e:
                logger.warning(f"Failed to check GPU {i}: {e}")
        
        if device_info['type'] == 'cuda':
            torch.cuda.set_device(best_gpu)
            logger.info(f"‚úÖ Selected GPU {best_gpu}: {device_info['name']} ({device_info['memory']:.1f}GB)")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ NPU (Intel Neural Compute Stick, etc.)
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ Intel NPU
        if os.path.exists('/dev/intel_npu0'):
            device_info = {
                'type': 'npu',
                'id': 0,
                'name': 'Intel NPU',
                'memory': 16  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å NPU
            }
            logger.info("‚úÖ Found Intel NPU")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä—É–≥–∏—Ö NPU
        elif os.path.exists('/dev/npu0'):
            device_info = {
                'type': 'npu',
                'id': 0,
                'name': 'Generic NPU',
                'memory': 8
            }
            logger.info("‚úÖ Found Generic NPU")
    except Exception as e:
        logger.debug(f"NPU check failed: {e}")
    
    if device_info['type'] == 'cpu':
        logger.info("‚ö†Ô∏è Using CPU (no GPU/NPU available)")
    
    return device_info

def optimize_for_device(device_info: Dict[str, Any]) -> None:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ —Ä–µ—Å—É—Ä—Å–æ–≤."""
    if device_info['type'] == 'cuda':
        # üöÄ –ù–û–í–´–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –†–ï–°–£–†–°–û–í GPU (50-80%)
        total_memory_gb = device_info['memory']
        max_usable_memory_gb = total_memory_gb * 0.8  # –ú–∞–∫—Å–∏–º—É–º 80%
        min_usable_memory_gb = total_memory_gb * 0.5  # –ú–∏–Ω–∏–º—É–º 50%
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –ø–∞–º—è—Ç–∏
        memory_fraction = 0.8  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞–∫—Å–∏–º—É–º 80%
        os.environ['CUDA_MEMORY_FRACTION'] = str(memory_fraction)
        
        # CUDA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        torch.backends.cudnn.benchmark = True
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        
        # üöÄ –ù–û–í–û–ï: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –ø–∞–º—è—Ç–∏
        if total_memory_gb >= 24:  # 24GB+ GPU
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –º–∞–∫—Å–∏–º—É–º 80% –ø–∞–º—è—Ç–∏
            max_tensor_size = int(max_usable_memory_gb * 0.8 * (1024**3))
            torch.cuda.set_per_process_memory_fraction(memory_fraction)
            logger.info(f"üöÄ High-memory GPU optimizations enabled (max: {max_usable_memory_gb:.1f}GB, {memory_fraction*100:.0f}%)")
            
        elif total_memory_gb >= 12:  # 12-24GB GPU
            torch.backends.cudnn.benchmark = True
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –º–∞–∫—Å–∏–º—É–º 75% –ø–∞–º—è—Ç–∏
            memory_fraction = 0.75
            os.environ['CUDA_MEMORY_FRACTION'] = str(memory_fraction)
            torch.cuda.set_per_process_memory_fraction(memory_fraction)
            logger.info(f"‚ö° Medium-memory GPU optimizations enabled (max: {max_usable_memory_gb:.1f}GB, {memory_fraction*100:.0f}%)")
            
        else:  # <12GB GPU
            torch.backends.cudnn.benchmark = False
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –º–∞–∫—Å–∏–º—É–º 70% –ø–∞–º—è—Ç–∏
            memory_fraction = 0.7
            os.environ['CUDA_MEMORY_FRACTION'] = str(memory_fraction)
            torch.cuda.set_per_process_memory_fraction(memory_fraction)
            logger.info(f"üîß Low-memory GPU optimizations enabled (max: {max_usable_memory_gb:.1f}GB, {memory_fraction*100:.0f}%)")
        
        # üöÄ –ù–û–í–û–ï: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ CUDA
        torch.cuda.empty_cache()
        logger.info(f"üßπ CUDA cache cleared, memory fraction set to {memory_fraction*100:.0f}%")
    
    elif device_info['type'] == 'npu':
        # üöÄ –ù–û–í–´–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø NPU (50-80%)
        os.environ['INTEL_NPU_DEVICE'] = f"npu{device_info['id']}"
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è NPU
        max_cpu_percent = 80
        max_memory_percent = 80
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è NPU
        os.environ['INTEL_NPU_MAX_CPU_USAGE'] = str(max_cpu_percent)
        os.environ['INTEL_NPU_MAX_MEMORY_USAGE'] = str(max_memory_percent)
        
        logger.info(f"üöÄ NPU optimizations enabled (max CPU: {max_cpu_percent}%, max memory: {max_memory_percent}%)")
    
    # –û–±—â–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    torch.set_num_threads(min(8, os.cpu_count()))
    
    logger.info(f"‚úÖ Device optimization completed for {device_info['type']} ({device_info['name']})")

def manage_gpu_memory(device_info: Dict[str, Any], operation: str = "check") -> None:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é GPU —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ 50-80%."""
    if device_info['type'] != 'cuda':
        return
        
    try:
        if operation == "clear":
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ CUDA
            torch.cuda.empty_cache()
            logger.info("üßπ GPU memory cache cleared")
            
        elif operation == "check":
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
            allocated = torch.cuda.memory_allocated(device_info['id']) / (1024**3)
            reserved = torch.cuda.memory_reserved(device_info['id']) / (1024**3)
            total = device_info['memory']
            
            usage_percent = (allocated / total) * 100
            
            if usage_percent > 80:
                logger.warning(f"‚ö†Ô∏è GPU memory usage: {usage_percent:.1f}% > 80% limit")
                torch.cuda.empty_cache()
                logger.info("üßπ GPU memory cache cleared due to high usage")
            elif usage_percent > 70:
                logger.info(f"‚ÑπÔ∏è GPU memory usage: {usage_percent:.1f}% (approaching 80% limit)")
            else:
                logger.info(f"‚úÖ GPU memory usage: {usage_percent:.1f}% (within limits)")
                
    except Exception as e:
        logger.warning(f"GPU memory management error: {e}")

# Absolute cache paths inside the container
# Fixed paths for proper model loading in cog runtime
WEIGHTS_ROOT = "/src/model_files"
SDXL_CACHE_DIR = "/src/sdxl-cache"
CONTROLNET_CACHE_DIR = "/src/sdxl-cache"
REFS_DIR = "/src/model_files/refs"

# ControlNet local subfolders (pre-downloaded in build steps)
CONTROLNET_CANNY_DIR = os.path.join(CONTROLNET_CACHE_DIR, "controlnet-canny-sdxl-1.0")
# Soft-edge variant is sometimes distributed as HED for SDXL. Support both names.
CONTROLNET_HED_DIR = os.path.join(CONTROLNET_CACHE_DIR, "controlnet-hed-sdxl-1.0")
CONTROLNET_SOFTEDGE_DIR = os.path.join(CONTROLNET_CACHE_DIR, "controlnet-softedge-sdxl-1.0")
# Public alternative edge-like model available without gating
CONTROLNET_LINEART_DIR = os.path.join(CONTROLNET_CACHE_DIR, "controlnet-lineart-sdxl-1.0")

# HF repo ids for fallback when local cache is not baked into the image
SDXL_REPO_ID = "stabilityai/stable-diffusion-xl-base-1.0"
CONTROLNET_CANNY_REPO_ID = "diffusers/controlnet-canny-sdxl-1.0"
# –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–±–æ—á–∏–π repo ID –¥–ª—è Lineart ControlNet - SD 1.5 –≤–µ—Ä—Å–∏—è
CONTROLNET_LINEART_REPO_ID = "lllyasviel/control_v11p_sd15_scribble"


def hex_to_rgb(hex_color: str) -> Tuple[int, int, int]:
    h = hex_color.strip().lstrip("#")
    return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))


def average_color_from_image(image_path: str) -> Tuple[int, int, int]:
    img = Image.open(image_path).convert("RGB")
    arr = np.asarray(img)
    mean = arr.reshape(-1, 3).mean(axis=0)
    return tuple(int(x) for x in mean.tolist())


def sample_color_for_name(color_name: str) -> Tuple[int, int, int]:
    color_folder = os.path.join(REFS_DIR, color_name)
    if os.path.isdir(color_folder):
        candidates: List[str] = []
        for fn in os.listdir(color_folder):
            if fn.lower().endswith((".png", ".jpg", ".jpeg")):
                candidates.append(os.path.join(color_folder, fn))
        if candidates:
            choice = random.choice(candidates)
            return average_color_from_image(choice)
    # Fallback simple mapping (extend as needed)
    named = {
        "black": (20, 20, 20),
        "white": (235, 235, 235),
        "red": (180, 40, 40),
        "green": (40, 160, 80),
        "blue": (40, 80, 180),
        "gray": (128, 128, 128),
        "brown": (120, 80, 50),
    }
    return named.get(color_name.lower(), (127, 127, 127))


def build_color_map(colors: List[Dict[str, Any]], size: Tuple[int, int], out_path: str) -> Image.Image:
    width, height = size
    canvas = Image.new("RGB", (width, height))
    draw = Image.new("RGB", (width, height))
    # Normalize proportions
    props = [max(0.0, float(c.get("proportion", 0))) for c in colors]
    total = sum(props) or 1.0
    props = [p / total for p in props]

    x0 = 0
    for c, p in zip(colors, props):
        w = int(round(p * width))
        if w <= 0:
            continue
        color = sample_color_for_name(c.get("name", "gray"))
        for x in range(x0, min(x0 + w, width)):
            for y in range(height):
                canvas.putpixel((x, y), color)
        x0 += w

    canvas.save(out_path)
    return canvas


def canny_edge_from_image(image: Image.Image, low_threshold: int, high_threshold: int) -> np.ndarray:
    # Convert PIL to OpenCV format
    img_array = np.array(image)
    if img_array.shape[2] == 3:  # RGB
        img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        img_gray = img_array

    # Apply Canny edge detection
    edges = cv2.Canny(img_gray, low_threshold, high_threshold)
    
    # Convert back to PIL format
    return Image.fromarray(edges)


def select_controlnet_by_angle(angle: int, controlnet_canny: ControlNetModel, 
                              controlnet_softedge: ControlNetModel, 
                              controlnet_lineart: ControlNetModel) -> ControlNetModel:
    """Select ControlNet based on angle for optimal edge detection."""
    # Normalize angle to 0-360 range
    angle = angle % 360
    
    # For diagonal angles (30-60, 120-150, 210-240, 300-330), prefer Lineart
    if 30 <= angle <= 60 or 120 <= angle <= 150 or 210 <= angle <= 240 or 300 <= angle <= 330:
        if controlnet_lineart is not None:
            logger.info(f"Selected Lineart ControlNet for diagonal angle {angle}")
            return controlnet_lineart
        else:
            logger.warning("Lineart ControlNet not available, falling back to Canny")
    
    # For horizontal/vertical angles (0, 90, 180, 270), prefer Canny
    if angle in [0, 90, 180, 270]:
        if controlnet_canny is not None:
            logger.info(f"Selected Canny ControlNet for cardinal angle {angle}")
            return controlnet_canny
        else:
            logger.warning("Canny ControlNet not available, falling back to Softedge")
    
    # Default to Softedge for other angles
    if controlnet_softedge is not None:
        logger.info(f"Selected Softedge ControlNet for angle {angle}")
        return controlnet_softedge
    else:
        logger.warning("Softedge ControlNet not available, falling back to Canny")
        return controlnet_canny


class OptimizedPredictor(BasePredictor):
    def setup(self, weights: Optional[Path] = None) -> None:
        """Load the model into memory to make running multiple predictions efficient."""
        start_time = time.time()
        logger.info("Starting model setup...")
        
        # üöÄ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –í—ã–±–æ—Ä –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ª—É—á—à–µ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        self.device_info = select_best_device()
        optimize_for_device(self.device_info)
        
        # üöÄ –ù–û–í–û–ï: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
        self.resource_monitor = ResourceMonitor(self.device_info)
        self.resource_monitor.start_monitoring()
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–ª—è PyTorch
        if self.device_info['type'] == 'cuda':
            self.device = f"cuda:{self.device_info['id']}"
        elif self.device_info['type'] == 'npu':
            self.device = "cpu"  # NPU –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é –≤ diffusers
        else:
            self.device = "cpu"
        
        logger.info(f"üéØ Using device: {self.device} ({self.device_info['name']})")
        
        # üöÄ –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é GPU
        manage_gpu_memory(self.device_info, "check")

        # Load ControlNet models
        logger.info("Loading ControlNet models...")
        
        # Try to load ControlNet models from local cache first
        self.controlnet_canny = None
        self.controlnet_softedge = None
        self.controlnet_lineart = None
        
        try:
            if os.path.exists(CONTROLNET_CANNY_DIR):
                self.controlnet_canny = ControlNetModel.from_pretrained(CONTROLNET_CANNY_DIR)
                logger.info("Loaded Canny ControlNet from local cache")
            else:
                logger.info("Canny ControlNet not found in local cache, will download from HF")
                self.controlnet_canny = ControlNetModel.from_pretrained(CONTROLNET_CANNY_REPO_ID)
        except Exception as e:
            logger.warning(f"Failed to load Canny ControlNet: {e}")
            self.controlnet_canny = None

        try:
            if os.path.exists(CONTROLNET_HED_DIR):
                self.controlnet_softedge = ControlNetModel.from_pretrained(CONTROLNET_HED_DIR)
                logger.info("Loaded HED/Softedge ControlNet from local cache")
            elif os.path.exists(CONTROLNET_SOFTEDGE_DIR):
                self.controlnet_softedge = ControlNetModel.from_pretrained(CONTROLNET_SOFTEDGE_DIR)
                logger.info("Loaded Softedge ControlNet from local cache")
            else:
                logger.info("Softedge ControlNet not found in local cache, will download from HF")
                self.controlnet_softedge = ControlNetModel.from_pretrained(CONTROLNET_CANNY_REPO_ID)
        except Exception as e:
            logger.warning(f"Failed to load Softedge ControlNet: {e}")
            self.controlnet_softedge = None

        try:
            if os.path.exists(CONTROLNET_LINEART_DIR):
                self.controlnet_lineart = ControlNetModel.from_pretrained(CONTROLNET_LINEART_DIR)
                logger.info("Loaded Lineart ControlNet from local cache")
            else:
                logger.info("Lineart ControlNet not found in local cache, will download from HF")
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–±–æ—á–∏–π repo ID - SD 1.5 –≤–µ—Ä—Å–∏—è
                self.controlnet_lineart = ControlNetModel.from_pretrained(CONTROLNET_LINEART_REPO_ID)
        except Exception as e:
            logger.warning(f"Failed to load Lineart ControlNet: {e}")
            self.controlnet_lineart = None

        # Initialize SDXL pipeline with ControlNet
        logger.info("Initializing SDXL pipeline...")
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –Ω–∞–¥–µ–∂–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –ø–æ–ª–Ω—ã–º fallback
        self.has_controlnet = False
        self.pipe = None
        
        # –ü–æ–ø—ã—Ç–∫–∞ 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å ControlNet (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        initial_controlnet = self.controlnet_canny or self.controlnet_softedge or self.controlnet_lineart
        
        if initial_controlnet is not None:
            try:
                logger.info("Attempting to initialize SDXL ControlNet pipeline...")
                self.pipe = StableDiffusionXLControlNetPipeline.from_pretrained(
                    SDXL_REPO_ID,
                    controlnet=initial_controlnet,
                    torch_dtype=torch.float16,
                    use_safetensors=True,
                    variant="fp16",
                    safety_checker=None,
                    requires_safety_checker=False,
                ).to(self.device)
                self.has_controlnet = True
                logger.info("‚úÖ Successfully initialized SDXL ControlNet pipeline")
            except Exception as e:
                logger.warning(f"‚ùå ControlNet pipeline initialization failed: {e}")
                self.pipe = None
                self.has_controlnet = False
        
        # –ü–æ–ø—ã—Ç–∫–∞ 2: Fallback –Ω–∞ –±–∞–∑–æ–≤—ã–π SDXL
        if self.pipe is None:
            try:
                logger.info("Falling back to basic SDXL pipeline...")
                from diffusers import StableDiffusionXLPipeline
                self.pipe = StableDiffusionXLPipeline.from_pretrained(
                    SDXL_REPO_ID,
                    torch_dtype=torch.float16,
                    use_safetensors=True,
                    variant="fp16",
                    safety_checker=None,
                    requires_safety_checker=False,
                ).to(self.device)
                self.has_controlnet = False
                logger.info("‚úÖ Successfully initialized basic SDXL pipeline")
            except Exception as e:
                logger.error(f"‚ùå Basic SDXL pipeline initialization failed: {e}")
                raise RuntimeError(f"Failed to initialize any pipeline: {e}")
        
        if self.pipe is None:
            raise RuntimeError("Pipeline initialization failed completely")

        # Attach LoRA and Textual Inversion
        lora_path = "./model_files/rubber-tile-lora-v4_sdxl_lora.safetensors"
        ti_path = "./model_files/rubber-tile-lora-v4_sdxl_embeddings.safetensors"
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ LoRA —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        if os.path.exists(lora_path):
            try:
                logger.info("Loading LoRA weights...")
                self.pipe.load_lora_weights(lora_path)
                # Fuse for runtime speed
                self.pipe.fuse_lora()
                logger.info("‚úÖ LoRA weights loaded successfully")
            except Exception as e:
                logger.error(f"‚ùå Failed to load LoRA weights: {e}")
                raise RuntimeError(f"LoRA weights loading failed: {e}")
        else:
            logger.error(f"‚ùå LoRA weights not found at {lora_path}")
            raise RuntimeError(f"LoRA weights not found at {lora_path}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ Textual Inversion —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        if os.path.exists(ti_path):
            try:
                logger.info("Loading Textual Inversion embeddings...")
                # Try standard loader first (may fail for SDXL dual-encoder TI formats)
                try:
                    self.pipe.load_textual_inversion(ti_path, token="<s0>")
                    logger.info("‚úÖ Textual Inversion loaded with standard method")
                except Exception as e:
                    logger.warning(f"Standard TI load failed ({e}). Falling back to manual SDXL dual-encoder TI install...")
                    self._install_sdxl_textual_inversion_dual(ti_path, token_g="<s0>", token_l="<s0>")
                    logger.info("‚úÖ Textual Inversion loaded with manual method")
            except Exception as e:
                logger.error(f"‚ùå Failed to load Textual Inversion: {e}")
                raise RuntimeError(f"Textual Inversion loading failed: {e}")
        else:
            logger.error(f"‚ùå Textual inversion embeddings not found at {ti_path}")
            raise RuntimeError(f"Textual inversion embeddings not found at {ti_path}")

        # Scheduler —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            self.pipe.scheduler = EulerDiscreteScheduler.from_config(self.pipe.scheduler.config)
            logger.info("‚úÖ Scheduler configured successfully")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Scheduler configuration failed: {e}")

        # Basic runtime opts —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            if hasattr(self.pipe, "enable_vae_slicing"):
                self.pipe.enable_vae_slicing()
                logger.info("‚úÖ VAE slicing enabled")
            if hasattr(self.pipe, "enable_vae_tiling"):
                self.pipe.enable_vae_tiling()
                logger.info("‚úÖ VAE tiling enabled")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è VAE optimization failed: {e}")
        
        # Performance optimizations - –æ—Ç–∫–ª—é—á–µ–Ω torch.compile –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å CUDA Graph
        # if hasattr(torch, 'compile') and torch.__version__ >= "2.4.0":
        #     try:
        #         logger.info("Enabling torch.compile for performance...")
        #         self.pipe = torch.compile(self.pipe, mode="reduce-overhead")
        #     except Exception as e:
        #         logger.warning(f"torch.compile failed: {e}")
        
        # CUDA optimizations —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            if self.device_info['type'] == 'cuda':
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —É–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –≤ optimize_for_device()
                logger.info("‚úÖ CUDA optimizations applied")
            elif self.device_info['type'] == 'npu':
                logger.info("‚úÖ NPU optimizations applied")
            else:
                logger.info("‚úÖ CPU optimizations applied")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Device optimization failed: {e}")

        setup_time = time.time() - start_time
        logger.info(f"üéâ Model setup completed successfully in {setup_time:.2f}s")
        logger.info(f"üìä ControlNet enabled: {self.has_controlnet}")
        logger.info(f"üîß Pipeline type: {type(self.pipe).__name__}")
        logger.info(f"üöÄ Device: {self.device} ({self.device_info['name']})")
        logger.info(f"üíæ Device memory: {self.device_info['memory']:.1f}GB")

    def _parse_params_json(self, params_json: str) -> Dict[str, Any]:
        """Clean parsing of params_json with proper error handling."""
        try:
            # First, try to parse the input directly
            if not params_json:
                return {}
            
            # Handle potential double-escaped JSON from web interface
            params = json.loads(params_json)
            
                                                # If params_json contains another params_json, extract it
            if "params_json" in params:
                inner_json = params["params_json"]
                if isinstance(inner_json, str):
                    params = json.loads(inner_json)
                else:
                    params = inner_json
            
            # Validate and clean the parsed parameters
            cleaned_params = {}
            
            # Colors validation
            if "colors" in params:
                colors = params["colors"]
                if isinstance(colors, list):
                    cleaned_colors = []
                    for color_info in colors:
                        if isinstance(color_info, dict):
                            name = color_info.get("name", "").strip()
                            proportion = color_info.get("proportion", 0)
                            
                            # Validate proportion (should be 0-100)
                            try:
                                proportion = float(proportion)
                                if 0 <= proportion <= 100:
                                    cleaned_colors.append({
                                        "name": name.lower(),
                                        "proportion": proportion
                                    })
                                else:
                                    logger.warning(f"Invalid proportion {proportion}, must be 0-100")
                            except (ValueError, TypeError):
                                logger.warning(f"Invalid proportion value: {proportion}")
                    
                    cleaned_params["colors"] = cleaned_colors
            
            # Other parameters
            for key in ["angle", "seed", "quality"]:
                if key in params:
                    value = params[key]
                    if key == "angle":
                        try:
                            cleaned_params[key] = int(value) % 360
                        except (ValueError, TypeError):
                            cleaned_params[key] = 0
                    elif key == "seed":
                        try:
                            cleaned_params[key] = int(value)
                        except (ValueError, TypeError):
                            cleaned_params[key] = -1
                    elif key == "quality":
                        if value in ["preview", "standard", "high"]:
                            cleaned_params[key] = value
                        else:
                            cleaned_params[key] = "standard"
            
            # Overrides validation
            if "overrides" in params and isinstance(params["overrides"], dict):
                overrides = params["overrides"]
                cleaned_overrides = {}
                
                # ControlNet setting
                if "use_controlnet" in overrides:
                    cleaned_overrides["use_controlnet"] = bool(overrides["use_controlnet"])
                
                # Guidance scale
                if "guidance_scale" in overrides:
                    try:
                        guidance = float(overrides["guidance_scale"])
                        if 1.0 <= guidance <= 20.0:
                            cleaned_overrides["guidance_scale"] = guidance
                        else:
                            logger.warning(f"Invalid guidance_scale {guidance}, using default")
                    except (ValueError, TypeError):
                        logger.warning(f"Invalid guidance_scale value: {overrides['guidance_scale']}")
                
                # Steps overrides
                for key in ["num_inference_steps_preview", "num_inference_steps_final"]:
                    if key in overrides:
                        try:
                            steps = int(overrides[key])
                            if 1 <= steps <= 100:
                                cleaned_overrides[key] = steps
                            else:
                                logger.warning(f"Invalid {key} {steps}, using default")
                        except (ValueError, TypeError):
                            logger.warning(f"Invalid {key} value: {overrides[key]}")
                
                if cleaned_overrides:
                    cleaned_params["overrides"] = cleaned_overrides
            
            logger.info(f"Parsed parameters: {cleaned_params}")
            return cleaned_params
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error: {e}")
            raise ValueError(f"Invalid JSON format: {e}")
        except Exception as e:
            logger.error(f"Unexpected error parsing params: {e}")
            raise ValueError(f"Failed to parse parameters: {e}")

    def _build_prompt(self, colors: List[Dict[str, Any]]) -> str:
        """Build clean prompt from color information."""
        prompt_parts = ["ohwx_rubber_tile <s0><s1>"]
        
        # Add color proportions to prompt
        if colors:
            color_desc = []
            for color_info in colors:
                name = color_info.get("name", "").lower()
                proportion = color_info.get("proportion", 0)
                if proportion > 0:
                    # proportion —É–∂–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (0-100), –Ω–µ —É–º–Ω–æ–∂–∞–µ–º –Ω–∞ 100
                    percentage = int(proportion)
                    color_desc.append(f"{percentage}% {name}")
            
            if color_desc:
                prompt_parts.append(", ".join(color_desc))
        
        # Add quality descriptors
        prompt_parts.extend([
            "photorealistic rubber tile",
            "matte texture", 
            "top view",
            "rubber granules",
            "textured surface"
        ])
        
        return ", ".join(prompt_parts)

    def _should_use_controlnet(self, angle: int) -> Tuple[bool, str]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ControlNet –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —É–≥–ª–∞.
        
        Args:
            angle: –£–≥–æ–ª —É–∫–ª–∞–¥–∫–∏ –≤ –≥—Ä–∞–¥—É—Å–∞—Ö
            
        Returns:
            Tuple[bool, str]: (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å_controlnet, –ø—Ä–∏—á–∏–Ω–∞)
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —É–≥–ª–∞
        angle_norm = int(angle) % 180
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–≥–æ–ª 0¬∞ - –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π –±–µ–∑ ControlNet
        if angle_norm == 0:
            return False, "–£–≥–æ–ª 0¬∞ (–≤–∏–¥ —Å–≤–µ—Ä—Ö—É) - –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Ä–∞–∫—É—Ä—Å –±–µ–∑ ControlNet"
        
        # –î–ª—è –¥—Ä—É–≥–∏—Ö —É–≥–ª–æ–≤ - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ControlNet —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
        if angle_norm in (45, 135):
            return True, f"–£–≥–æ–ª {angle}¬∞ —Ç—Ä–µ–±—É–µ—Ç ControlNet –¥–ª—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è"
        elif angle_norm in (30, 60, 90, 120, 150):
            return True, f"–£–≥–æ–ª {angle}¬∞ —Ç—Ä–µ–±—É–µ—Ç ControlNet –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
        else:
            return True, f"–£–≥–æ–ª {angle}¬∞ —Ç—Ä–µ–±—É–µ—Ç ControlNet (–Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∫—É—Ä—Å)"

    def _get_controlnet_model(self, angle: int) -> Optional[Any]:
        """
        –í—ã–±–∏—Ä–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â—É—é ControlNet –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —É–≥–ª–∞.
        
        Args:
            angle: –£–≥–æ–ª —É–∫–ª–∞–¥–∫–∏ –≤ –≥—Ä–∞–¥—É—Å–∞—Ö
            
        Returns:
            ControlNet –º–æ–¥–µ–ª—å –∏–ª–∏ None
        """
        angle_norm = int(angle) % 180
        
        # –î–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö/–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö —É–≥–ª–æ–≤ - Canny
        if angle_norm in (0, 90):
            if self.controlnet_canny:
                return self.controlnet_canny
            elif self.controlnet_softedge:
                return self.controlnet_softedge
        
        # –î–ª—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—ã—Ö —É–≥–ª–æ–≤ - Lineart –∏–ª–∏ SoftEdge
        elif angle_norm in (30, 45, 60, 120, 135, 150):
            if self.controlnet_lineart:
                return self.controlnet_lineart
            elif self.controlnet_softedge:
                return self.controlnet_softedge
            elif self.controlnet_canny:
                return self.controlnet_canny
        
        # Fallback –Ω–∞ –ª—é–±—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
        for model in [self.controlnet_canny, self.controlnet_softedge, self.controlnet_lineart]:
            if model:
                return model
        
        return None

    def predict(
        self,
        params_json: str = Input(description="Business-oriented parameters JSON: colors, angle, seed, quality, overrides. –í–ê–ñ–ù–û: –£–≥–æ–ª 0¬∞ - –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Ä–∞–∫—É—Ä—Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –î—Ä—É–≥–∏–µ —É–≥–ª—ã —Ç—Ä–µ–±—É—é—Ç ControlNet –¥–ª—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è.")
    ) -> List[Path]:
        """Generate preview/final images using ControlNet color‚Äëcomposition guidance.

        Returns: [preview.png, final.png, colormap.png]
        """
        start_time = time.time()
        
        # üöÄ –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π
        logger.info("üîç Checking device resources before generation...")
        manage_gpu_memory(self.device_info, "check")
        
        # Parse and validate input parameters
        try:
            params = self._parse_params_json(params_json)
        except Exception as e:
            raise ValueError(f"Parameter validation failed: {e}")

        colors = params.get("colors", [])
        angle = int(params.get("angle", 0))
        seed = int(params.get("seed", -1))
        quality = str(params.get("quality", "standard"))
        overrides: Dict[str, Any] = params.get("overrides", {}) or {}

        logger.info(f"Generating with params: colors={len(colors)}, angle={angle}, quality={quality}, seed={seed}")
        
        # üöÄ –ù–û–í–û–ï: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤
        if hasattr(self, 'resource_monitor'):
            resource_summary = self.resource_monitor.get_resource_summary()
            logger.info(f"üìä Resource status: {resource_summary}")

        # Defaults and quality profiles
        if quality == "preview":
            steps_preview, steps_final = 24, 32
            size_preview, size_final = (512, 512), (1024, 1024)
        elif quality == "high":
            steps_preview, steps_final = 32, 50
            size_preview, size_final = (512, 512), (1024, 1024)
        else:  # standard
            steps_preview, steps_final = 24, 40
            size_preview, size_final = (512, 512), (1024, 1024)

        # Apply overrides
        num_inference_steps_preview = int(overrides.get("num_inference_steps_preview", steps_preview))
        num_inference_steps_final = int(overrides.get("num_inference_steps_final", steps_final))
        guidance_scale = float(overrides.get("guidance_scale", 7.5))

        # Build clean prompt
        base_prompt = self._build_prompt(colors)
        logger.info(f"Generated prompt: {base_prompt}")

        negative_prompt = overrides.get(
            "negative_prompt",
            "object, blurry, worst quality, low quality, deformed, watermark, 3d render, cartoon, abstract, smooth, flat",
        )

        # Generator
        generator = torch.manual_seed(seed) if seed != -1 else torch.Generator(device=self.device)
        if seed == -1:
            seed = generator.seed()

        # Create color map and corresponding control image (edge map)
        colormap_path = "/tmp/colormap.png"
        logger.info(f"Building color map for {len(colors)} colors")
        colormap_img = build_color_map(colors, size_final, colormap_path)
        logger.info(f"Color map saved to {colormap_path}")

        # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –õ–æ–≥–∏–∫–∞ —É–≥–ª–æ–≤ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ –º–æ–¥–µ–ª–∏
        should_use_controlnet, reason = self._should_use_controlnet(angle)
        use_controlnet_by_angle = should_use_controlnet
        
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π override ControlNet
        user_controlnet_setting = overrides.get("use_controlnet", None)
        
        if user_controlnet_setting is not None:
            use_controlnet = bool(user_controlnet_setting)
            if use_controlnet != use_controlnet_by_angle:
                logger.warning(f"‚ö†Ô∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏–ª ControlNet: {use_controlnet} (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: {use_controlnet_by_angle})")
                logger.warning(f"‚ö†Ô∏è –ü—Ä–∏—á–∏–Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {reason}")
        else:
            use_controlnet = use_controlnet_by_angle
            
        logger.info(f"ControlNet —Ä–µ—à–µ–Ω–∏–µ: {use_controlnet} - {reason}")
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å ControlNet
        control_preview = None
        control_final = None
        
        if use_controlnet and self.has_controlnet:
            try:
        # Select controlnet by angle
                selected_cn = select_controlnet_by_angle(
                    angle, self.controlnet_canny, self.controlnet_softedge, self.controlnet_lineart
                )
                if selected_cn is not None:
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º ControlNet
                    if hasattr(self.pipe, 'controlnet'):
                        self.pipe.controlnet = selected_cn
                        logger.info(f"‚úÖ ControlNet set for angle {angle}")

                        # Prepare edge maps for preview/final
                        logger.info("Generating edge maps...")
                        control_preview = canny_edge_from_image(colormap_img.resize(size_preview, Image.NEAREST), 80, 160)
                        control_final = canny_edge_from_image(colormap_img.resize(size_final, Image.NEAREST), 100, 200)
                        logger.info("‚úÖ Edge maps generated successfully")
                    else:
                        logger.warning("‚ö†Ô∏è Pipeline does not support ControlNet")
                        use_controlnet = False
                else:
                    logger.warning("‚ö†Ô∏è No ControlNet available for this angle")
                    use_controlnet = False
            except Exception as e:
                logger.error(f"‚ùå ControlNet setup failed: {e}")
                use_controlnet = False
                control_preview = None
                control_final = None
        else:
            logger.info("‚ÑπÔ∏è ControlNet disabled (user preference or not available)")

        # Generate preview first (fast)
        preview_start = time.time()
        logger.info(f"Generating preview with {num_inference_steps_preview} steps, guidance_scale={guidance_scale}")
        logger.info(f"ControlNet status: enabled={use_controlnet}, available={self.has_controlnet}, image={control_preview is not None}")
        
        try:
            # Prepare generation parameters
            gen_params = {
                "prompt": base_prompt,
                "negative_prompt": negative_prompt,
                "width": size_preview[0],
                "height": size_preview[1],
                "num_inference_steps": num_inference_steps_preview,
                "guidance_scale": guidance_scale,
                "generator": generator,
            }
            
            # Add ControlNet image if enabled and available
            if use_controlnet and control_preview is not None and self.has_controlnet:
                gen_params["image"] = control_preview
                logger.info("‚úÖ Using ControlNet for preview generation")
            else:
                logger.info("‚ÑπÔ∏è Preview generation without ControlNet")
            
            preview = self.pipe(**gen_params).images[0]
            preview_time = time.time() - preview_start
            logger.info(f"‚úÖ Preview generated successfully in {preview_time:.2f}s")
        except Exception as e:
            logger.error(f"‚ùå Preview generation failed: {e}")
            raise RuntimeError(f"Preview generation failed: {e}")

        # Generate final (quality)
        final_start = time.time()
        logger.info(f"Generating final image with {num_inference_steps_final} steps")
        
        try:
            # Prepare generation parameters
            gen_params = {
                "prompt": base_prompt,
                "negative_prompt": negative_prompt,
                "width": size_final[0],
                "height": size_final[1],
                "num_inference_steps": num_inference_steps_final,
                "guidance_scale": guidance_scale,
                "generator": generator,
            }
            
            # Add ControlNet image if enabled and available
            if use_controlnet and control_final is not None and self.has_controlnet:
                gen_params["image"] = control_final
                logger.info("‚úÖ Using ControlNet for final generation")
            else:
                logger.info("‚ÑπÔ∏è Final generation without ControlNet")
            
            final = self.pipe(**gen_params).images[0]
            final_time = time.time() - final_start
            logger.info(f"‚úÖ Final image generated successfully in {final_time:.2f}s")
        except Exception as e:
            logger.error(f"‚ùå Final generation failed: {e}")
            raise RuntimeError(f"Final generation failed: {e}")

        # Save outputs with improved error handling
        try:
            preview_path = "/tmp/preview.png"
            final_path = "/tmp/final.png"
            preview.save(preview_path)
            final.save(final_path)
            logger.info("‚úÖ Images saved successfully")
        except Exception as e:
            logger.error(f"‚ùå Failed to save images: {e}")
            raise RuntimeError(f"Failed to save images: {e}")

        total_time = time.time() - start_time
        logger.info(f"üéâ Generation completed successfully in {total_time:.2f}s")
        logger.info(f"üìÅ Outputs: preview={preview_path}, final={final_path}, colormap={colormap_path}")
        logger.info(f"üìä Final stats: ControlNet={use_controlnet}, Steps={num_inference_steps_final}, Quality={quality}")
        
        # üöÄ –ù–û–í–û–ï: –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        logger.info("üßπ Cleaning up device resources after generation...")
        manage_gpu_memory(self.device_info, "clear")
        
        # üöÄ –ù–û–í–û–ï: –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ —Ä–µ—Å—É—Ä—Å–∞–º
        if hasattr(self, 'resource_monitor'):
            final_resource_summary = self.resource_monitor.get_resource_summary()
            logger.info(f"üìä Final resource summary: {final_resource_summary}")

        return [Path(preview_path), Path(final_path), Path(colormap_path)]

    def _install_sdxl_textual_inversion_dual(self, ti_path: str, token_g: str, token_l: str) -> None:
        """Install SDXL textual inversion that contains separate embeddings for CLIP-G and CLIP-L encoders.

        The `safetensors` file is expected to contain keys 'clip_g' and 'clip_l'.
        We will add tokens to both tokenizers and set the corresponding encoder embeddings.
        """
        state = load_safetensors(ti_path)
        emb_g = state.get("clip_g")
        emb_l = state.get("clip_l")

        if emb_g is None or emb_l is None:
            raise ValueError("Textual inversion file must contain 'clip_g' and 'clip_l' tensors for SDXL.")

        # Tokenizer/encoder mapping: 'g' ‚Üí text_encoder_2 (bigG/1280), 'l' ‚Üí text_encoder (Large/768)
        tokenizer_g = getattr(self.pipe, "tokenizer_2", None)
        tokenizer_l = getattr(self.pipe, "tokenizer", None)
        encoder_g = getattr(self.pipe, "text_encoder_2", None)
        encoder_l = getattr(self.pipe, "text_encoder", None)

        if any(x is None for x in (tokenizer_g, tokenizer_l, encoder_g, encoder_l)):
            raise RuntimeError("Pipeline is missing SDXL tokenizers/encoders required for TI installation.")

        # Determine number of tokens in the TI file
        num_tokens = emb_g.shape[0] if len(emb_g.shape) > 1 else 1
        logger.info(f"Textual inversion contains {num_tokens} token(s)")
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–ª–æ–≤–∞—Ä—è
        logger.info(f"TI state dict keys: {list(state.keys())}")
        logger.info(f"clip_g shape: {emb_g.shape}, clip_l shape: {emb_l.shape}")

        # Generate token names if multiple tokens
        if num_tokens == 1:
            tokens_g = [token_g]
            tokens_l = [token_l]
        else:
            # For multiple tokens, use <s0>, <s1>, <s2>, etc.
            tokens_g = [f"<s{i}>" for i in range(num_tokens)]
            tokens_l = [f"<s{i}>" for i in range(num_tokens)]

        # Ensure tokens exist in tokenizers
        added_g = tokenizer_g.add_tokens(tokens_g, special_tokens=True)
        added_l = tokenizer_l.add_tokens(tokens_l, special_tokens=True)

        if added_g > 0:
            encoder_g.resize_token_embeddings(len(tokenizer_g))
        if added_l > 0:
            encoder_l.resize_token_embeddings(len(tokenizer_l))

        with torch.no_grad():
            emb_layer_g = encoder_g.get_input_embeddings()
            emb_layer_l = encoder_l.get_input_embeddings()

            # Cast to encoder dtype/device
            emb_g_cast = emb_g.to(dtype=emb_layer_g.weight.dtype, device=emb_layer_g.weight.device)
            emb_l_cast = emb_l.to(dtype=emb_layer_l.weight.dtype, device=emb_layer_l.weight.device)

            # Check embedding dimensions (should match the embedding size of each encoder)
            if emb_g_cast.shape[-1] != emb_layer_g.weight.shape[-1]:
                raise ValueError(f"clip_g embedding dimension {emb_g_cast.shape[-1]} does not match text_encoder_2 embedding size {emb_layer_g.weight.shape[-1]}")
            if emb_l_cast.shape[-1] != emb_layer_l.weight.shape[-1]:
                raise ValueError(f"clip_l embedding dimension {emb_l_cast.shape[-1]} does not match text_encoder embedding size {emb_layer_l.weight.weight.shape[-1]}")

            # Set embeddings for each token
            for i, (token_g_name, token_l_name) in enumerate(zip(tokens_g, tokens_l)):
                token_id_g = tokenizer_g.convert_tokens_to_ids(token_g_name)
                token_id_l = tokenizer_l.convert_tokens_to_ids(token_l_name)

                # Extract embedding for this token
                if num_tokens == 1:
                    emb_g_token = emb_g_cast.squeeze(0) if len(emb_g_cast.shape) > 1 else emb_g_cast
                    emb_l_token = emb_l_cast.squeeze(0) if len(emb_l_cast.shape) > 1 else emb_l_cast
                else:
                    emb_g_token = emb_g_cast[i]
                    emb_l_token = emb_l_cast[i]

                # Set the embeddings for the specific token positions
                emb_layer_g.weight[token_id_g] = emb_g_token
                emb_layer_l.weight[token_id_l] = emb_l_token

        logger.info(f"SDXL textual inversion installed manually for {num_tokens} token(s): {tokens_g}")
    
    def __del__(self):
        """–î–µ—Å—Ç—Ä—É–∫—Ç–æ—Ä –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        if hasattr(self, 'resource_monitor'):
            self.resource_monitor.stop_monitoring()
            logger.info("üõë Resource monitoring stopped in destructor")