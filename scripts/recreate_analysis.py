#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
"""

import json
import os
from pathlib import Path
from datetime import datetime
import re

def parse_log_file(log_file_path):
    """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª –ª–æ–≥–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    logs = []
    
    with open(log_file_path, 'r', encoding='utf-8') as f:
        content = f.read().strip()
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–æ–≤
    log_entries = content.split('\n')
    
    for entry in log_entries:
        if not entry.strip():
            continue
            
        # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        # –§–æ—Ä–º–∞—Ç: [2025-09-12T20:23:20.410284] [INFO] content
        timestamp_match = re.match(r'\[(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})\.\d+\] \[(INFO|ERROR|WARNING)\] (.+)', entry)
        if timestamp_match:
            timestamp_str = timestamp_match.group(1).replace('T', ' ')
            log_level = timestamp_match.group(2)
            content = timestamp_match.group(3)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ª–æ–≥–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
            log_type = "info"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–æ–ª—å–∫–æ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
            if "‚ñ≤" in content or "warning" in content.lower():
                log_type = "warning"
            elif "‚ùå" in content or "error" in content.lower() or ("–æ—à–∏–±–∫–∞" in content and "‚ùå" not in content):
                log_type = "error"
            elif "–≤–µ—Ä—Å–∏—è" in content.lower() and ("–Ω–µ –Ω–∞–π–¥–µ–Ω–∞" in content or "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞" in content):
                log_type = "version_issue"
            elif "–ø—Ä–µ—Å–µ—Ç" in content.lower() and "—Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏" in content:
                log_type = "preset_error"
            else:
                # –î–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (‚úÖ) –≤—Å–µ–≥–¥–∞ info, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —É—Ä–æ–≤–Ω—è –≤ —Ñ–∞–π–ª–µ
                log_type = "info"
            
            logs.append({
                "timestamp": timestamp_str,
                "content": content,
                "type": log_type
            })
    
    return logs

def create_session_analysis(log_file_path, logs):
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Å—Å–∏–∏"""
    filename = Path(log_file_path).name
    session_id = filename.replace('.log', '')
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Å—Å–∏–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    parts = session_id.split('_')
    version = parts[1] if len(parts) > 1 else "unknown"
    hash_id = parts[2] if len(parts) > 2 else "unknown"
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = {
        "total_logs": len(logs),
        "warnings": sum(1 for log in logs if log["type"] == "warning"),
        "errors": sum(1 for log in logs if log["type"] == "error"),
        "version_issues": sum(1 for log in logs if log["type"] == "version_issue"),
        "preset_errors": sum(1 for log in logs if log["type"] == "preset_error")
    }
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è
    if logs:
        start_time = logs[0]["timestamp"]
        end_time = logs[-1]["timestamp"]
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        try:
            start_dt = datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            end_dt = datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")
            duration = str(end_dt - start_dt)
        except:
            duration = "unknown"
    else:
        start_time = "unknown"
        end_time = "unknown"
        duration = "unknown"
    
    session_info = {
        "session_id": session_id,
        "start_time": start_time,
        "end_time": end_time,
        "duration": duration,
        "version": version,
        "hash_id": hash_id
    }
    
    analysis_data = {
        "session_info": session_info,
        "statistics": stats,
        "all_logs": logs,
        "analysis_timestamp": datetime.now().isoformat()
    }
    
    return analysis_data

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logs_dir = Path("docs/reports/gui_logs/realtime")
    
    if not logs_dir.exists():
        print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã –ª–æ–≥–æ–≤
    log_files = list(logs_dir.glob("*.log"))
    
    if not log_files:
        print("‚ùå –§–∞–π–ª—ã –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(log_files)} —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤ –¥–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è")
    
    for log_file in log_files:
        print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {log_file.name}")
        
        # –ü–∞—Ä—Å–∏–º –ª–æ–≥
        logs = parse_log_file(log_file)
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑
        analysis_data = create_session_analysis(log_file, logs)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –∞–Ω–∞–ª–∏–∑–∞
        analysis_file = log_file.parent / f"{log_file.stem}_analysis.json"
        with open(analysis_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω: {analysis_file.name}")
        print(f"  - –õ–æ–≥–æ–≤: {analysis_data['statistics']['total_logs']}")
        print(f"  - –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {analysis_data['statistics']['warnings']}")
        print(f"  - –û—à–∏–±–∫–∏: {analysis_data['statistics']['errors']}")
        print(f"  - –ü—Ä–æ–±–ª–µ–º—ã —Å –≤–µ—Ä—Å–∏—è–º–∏: {analysis_data['statistics']['version_issues']}")
        print(f"  - –û—à–∏–±–∫–∏ –ø—Ä–µ—Å–µ—Ç–æ–≤: {analysis_data['statistics']['preset_errors']}")
        print()

if __name__ == "__main__":
    main()
